{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A — Linear & Polynomial Regression (Analytic)\n",
    "\n",
    "We will explore **linear regression** and **polynomial regression** using a synthetic dataset (`synthetic_regression.csv` with columns `x, y`). All solutions must use **analytic (closed-form)** formulas — **no gradient descent, no library `.fit()`** methods. Implement everything directly in **NumPy**.\n",
    "\n",
    "## Tasks\n",
    "1. **70/30 Train–Test Split (Unregularized)**\n",
    "   - Split the data into 70% train / 30% test (random, reproducible).\n",
    "   - Fit the following models:\n",
    "     - Linear regression (polynomial degree 1),\n",
    "     - Polynomial regression with degrees {2, 5, 10, 15}.\n",
    "   - For each model, build the design matrix explicitly:  \n",
    "     $\\\\Phi(x) = [1, x, x^2, \\\\dots, x^d]$.\n",
    "   - Solve using the normal equations:  \n",
    "     $\\\\hat\\\\theta = (\\\\Phi^\\\\top\\\\Phi)^{-1}\\\\Phi^\\\\top y$ (or use the pseudoinverse if singular).\n",
    "   - Compute **training error** and **test error**.\n",
    "   - Plot (a) the dataset points with all model fits on one figure, and (b) a **bar chart** of training vs test errors.\n",
    "\n",
    "2. **10-Fold Cross-Validation (Unregularized)**\n",
    "   - Implement 10-fold CV yourself (shuffle indices once, split into folds).\n",
    "   - For each degree {1, 2, 5, 10, 15}, compute the **average test error** across folds.\n",
    "   - Plot a **bar chart** comparing the average test error across all models.\n",
    "\n",
    "3. **Repeat (1) and (2) with Ridge Regularization**\n",
    "   - Use ridge regression with: $\\\\hat\\\\theta_\\\\lambda = (\\\\Phi^\\\\top\\\\Phi + \\\\lambda I)^{-1}\\\\Phi^\\\\top y$.\n",
    "   - **Take $\\\\lambda = 1$** (fixed).\n",
    "   - Show the same plots: fitted curves, bar chart of train/test errors, and bar chart of 10-fold average test errors.\n",
    "\n",
    "### Notes\n",
    "- Report **\\\"error\\\"** instead of MSE on your plots/prints.\n",
    "- If any bar chart scale makes some bars invisible, **use a logarithmic y-axis**: `plt.yscale(\"log\")`.\n",
    "- Keep your code structured and use the provided skeleton below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Skeleton (fill the TODOs)\n",
    "Update the CSV path to where you saved `synthetic_regression.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def design_matrix_poly_1d(x_column: np.ndarray, degree: int, include_bias: bool=True) -> np.ndarray:\n",
    "    \"\"\"Return Vandermonde-style design matrix [1, x, x^2, ..., x^degree].\"\"\"\n",
    "    x = x_column.reshape(-1)\n",
    "    start = 0 if include_bias else 1\n",
    "    cols = [x**p for p in range(start, degree+1)]\n",
    "    Phi = np.stack(cols, axis=1)\n",
    "    return Phi\n",
    "\n",
    "def normal_equation(Phi: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Closed-form least squares: theta = (Phi^T Phi)^{-1} Phi^T y (or pseudoinverse).\"\"\"\n",
    "    A = Phi.T @ Phi\n",
    "    b = Phi.T @ y\n",
    "    if np.linalg.matrix_rank(A) == A.shape[0]:\n",
    "        return np.linalg.inv(A) @ b\n",
    "    return np.linalg.pinv(Phi) @ y\n",
    "\n",
    "def ridge_closed_form(Phi: np.ndarray, y: np.ndarray, lam: float) -> np.ndarray:\n",
    "    \"\"\"Closed-form ridge: theta = (Phi^T Phi + λI)^{-1} Phi^T y.\"\"\"\n",
    "    d = Phi.shape[1]\n",
    "    A = Phi.T @ Phi + lam * np.eye(d)\n",
    "    b = Phi.T @ y\n",
    "    return np.linalg.inv(A) @ b\n",
    "\n",
    "def predict(Phi: np.ndarray, theta: np.ndarray) -> np.ndarray:\n",
    "    return Phi @ theta\n",
    "\n",
    "def err(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    r = y_true - y_pred\n",
    "    return float((r @ r) / r.size)\n",
    "\n",
    "def kfold_indices(n: int, K: int, seed: int = 0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    folds = np.array_split(idx, K)\n",
    "    splits = []\n",
    "    for k in range(K):\n",
    "        val_idx = folds[k]\n",
    "        train_idx = np.concatenate([folds[i] for i in range(K) if i != k])\n",
    "        splits.append((train_idx, val_idx))\n",
    "    return splits\n",
    "\n",
    "def train_test_split_indices(n: int, test_ratio: float = 0.3, seed: int = 42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    n_test = int(round(test_ratio * n))\n",
    "    test_idx = idx[:n_test]\n",
    "    train_idx = idx[n_test:]\n",
    "    return train_idx, test_idx\n",
    "\n",
    "def load_csv_xy(path: str):\n",
    "    xs, ys = [], []\n",
    "    with open(path, \"r\") as f:\n",
    "        rd = csv.DictReader(f)\n",
    "        for row in rd:\n",
    "            xs.append(float(row[\"x\"]))\n",
    "            ys.append(float(row[\"y\"]))\n",
    "    X = np.array(xs).reshape(-1, 1)\n",
    "    y = np.array(ys)\n",
    "    return X, y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
